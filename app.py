import streamlit as st
import pandas as pd
import numpy as np
from sqlalchemy import create_engine
import pymysql # Required by SQLAlchemy for MySQL+PyMySQL

# --- 1. Database Connection Configuration ---
# It's crucial to correctly configure your .streamlit/secrets.toml
#
# Example .streamlit/secrets.toml content:
# [mysql]
# host = "your_azure_mysql_server_name.mysql.database.azure.com" # e.g., "quant.mysql.database.azure.com"
# user = "your_username@your_server_name"                         # e.g., "quant@quant" (username@servername)
# password = "your_db_password"
# database = "your_database_name"                                # e.g., "stock_db"
# charset = "utf8mb4" # Use utf8mb4 for broader character support
# connect_timeout = 10
# read_timeout = 10
# write_timeout = 10

@st.cache_resource
def get_db_engine():
    """
    Creates and returns a SQLAlchemy engine for your Azure MySQL database.
    Caches the engine for performance in Streamlit.
    """
    if not st.secrets.get("mysql"):
        st.error("DB connection secrets not found. Please configure .streamlit/secrets.toml.")
        return None

    db_config = st.secrets["mysql"]
    
    try:
        # Construct the connection string using details from secrets
        # Azure MySQL usernames typically require 'username@servername' format.
        # Ensure 'user' in secrets.toml is already in this format.
        connection_string = (
            f"mysql+pymysql://{db_config['user']}:{db_config['password']}@"
            f"{db_config['host']}:3306/{db_config['database']}"
        )
        
        engine = create_engine(
            connection_string,
            pool_recycle=300,  # Recycle connections after 300 seconds (5 minutes)
            pool_pre_ping=True # Test connections before use
        )
        return engine
    except Exception as e:
        st.error(f"Error creating database engine: {e}")
        st.info("Please check your .streamlit/secrets.toml for correct Azure MySQL credentials.")
        return None

# --- 2. Streamlit App Layout and Data Loading ---

st.set_page_config(layout="wide", page_title="ì „ ì¢…ëª© ê°€ì¹˜ ì§€í‘œ ì¡°íšŒ")

st.title("ğŸ“Š ì „ ì¢…ëª© ìµœì‹  ê°€ì¹˜ ì§€í‘œ")
st.markdown("Azure Cloud MySQL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì „ ì¢…ëª©ì˜ ìµœì‹  ê¸°ë³¸ ì •ë³´ì™€ ê°€ì¹˜ ì§€í‘œë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")

# Get the database engine
db_engine = get_db_engine()

if db_engine is None:
    st.stop() # Stop the app if DB connection fails

# --- Data Loading Logic ---
st.info("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")

try:
    # Load ticker list
    # Assuming 'kor_ticker' stores 'ì¢…ê°€' as well, or you plan to merge 'kor_price' later.
    # For now, fetching 'ì¢…ê°€' from kor_ticker as it's often present there.
    ticker_list_query = """
    SELECT ì¢…ëª©ì½”ë“œ, ì¢…ëª©ëª…, ì¢…ê°€
    FROM kor_ticker
    WHERE ê¸°ì¤€ì¼ = (SELECT MAX(ê¸°ì¤€ì¼) FROM kor_ticker)
    AND ì¢…ëª©êµ¬ë¶„ = 'ë³´í†µì£¼';
    """
    ticker_list = pd.read_sql(ticker_list_query, con=db_engine)
    
    if ticker_list.empty:
        st.warning("`kor_ticker` í…Œì´ë¸”ì—ì„œ ì¢…ëª© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ë¹„ì–´ ìˆê±°ë‚˜ 'ë³´í†µì£¼'ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # Load valuation list
    # Assuming 'kor_value' has 'ì¢…ëª©ì½”ë“œ', 'ê¸°ì¤€ì¼', 'ì§€í‘œ' (e.g., 'PBR', 'PER'), 'ê°’'
    value_list_query = """
    SELECT ì¢…ëª©ì½”ë“œ, ì§€í‘œ, ê°’
    FROM kor_value
    WHERE ê¸°ì¤€ì¼ = (SELECT MAX(ê¸°ì¤€ì¼) FROM kor_value);
    """
    value_list = pd.read_sql(value_list_query, con=db_engine)

    if value_list.empty:
        st.warning("`kor_value` í…Œì´ë¸”ì—ì„œ ê°€ì¹˜ ì§€í‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    # Close the engine's connection pool after loading data
    db_engine.dispose()
    st.success("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° DB ì—°ê²° ì¢…ë£Œ ì™„ë£Œ!")

    # --- Data Processing ---
    if not value_list.empty:
        # Replace non-positive values with NaN for ratios (e.g., PER can be negative)
        # Note: Depending on your data, you might want to adjust this.
        # For simplicity, I'm using your original logic.
        value_list.loc[value_list['ê°’'] <= 0, 'ê°’'] = np.nan
        
        # Pivot the value_list to have indicators as columns
        value_pivot = value_list.pivot(index='ì¢…ëª©ì½”ë“œ', columns='ì§€í‘œ', values='ê°’')
    else:
        value_pivot = pd.DataFrame() # Create an empty DataFrame if no value data

    # Merge ticker information with pivoted valuation data
    data_bind = ticker_list[['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'ì¢…ê°€']].merge(value_pivot,
                                                        how='left',
                                                        on='ì¢…ëª©ì½”ë“œ')

    # --- Display Results ---
    st.subheader("ğŸ“‹ ì „ì²´ ì¢…ëª© ê°€ì¹˜ ì§€í‘œ")
    
    # Optional: Display some statistics or shape
    st.write(f"ì´ {len(data_bind)}ê°œ ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

    # Format numeric columns for better display
    numeric_cols = data_bind.select_dtypes(include=np.number).columns
    for col in numeric_cols:
        if col in ['ì¢…ê°€']: # Format as integer for price
            data_bind[col] = data_bind[col].apply(lambda x: f"{x:,.0f}" if pd.notna(x) else None)
        else: # Format other numeric values (like ratios) with 2 decimal places
            data_bind[col] = data_bind[col].apply(lambda x: f"{x:,.2f}" if pd.notna(x) else None)

    st.dataframe(data_bind, use_container_width=True)

    # --- Download as CSV ---
    @st.cache_data
    def convert_df_to_csv(df):
        # IMPORTANT: Avoid converting to string format for CSV export
        # because the user might want to perform calculations later.
        # Convert the original data_bind BEFORE formatting.
        return df.to_csv(index=False, encoding='utf-8-sig')

    # Create a clean DataFrame for CSV download (without display formatting)
    original_data_for_download = ticker_list[['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'ì¢…ê°€']].merge(
                                                value_list.pivot(index='ì¢…ëª©ì½”ë“œ', columns='ì§€í‘œ', values='ê°’'),
                                                how='left',
                                                on='ì¢…ëª©ì½”ë“œ')
    
    csv_file = convert_df_to_csv(original_data_for_download)

    st.download_button(
        label="ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
        data=csv_file,
        file_name=f"all_stock_valuation_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
        mime="text/csv"
    )

except Exception as e:
    st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.write("SQL ì¿¼ë¦¬ ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

st.sidebar.markdown("---")
st.sidebar.info("ë°ì´í„° ë¡œë”© ì‹œê°„ì€ DB í¬ê¸°ì™€ ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
st.sidebar.markdown("Â© 2025 Value Analyzer")
