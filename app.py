import streamlit as st
import pandas as pd
import numpy as np
from sqlalchemy import create_engine
import pymysql # Required by SQLAlchemy for mysql+pymysql
import statsmodels.api as sm
from scipy.stats import zscore
import matplotlib.pyplot as plt # Although not used for display here, kept for completeness

@st.cache_resource
def get_db_engine():
    """
    Creates and returns a SQLAlchemy engine for your Azure MySQL database.
    Caches the engine for performance in Streamlit sessions.
    """
    if not st.secrets.get("mysql"):
        st.error("DB connection secrets not found. Please configure .streamlit/secrets.toml.")
        return None

    db_config = st.secrets["mysql"]
    
    try:
        connection_string = (
            f"mysql+pymysql://{db_config['user']}:{db_config['password']}@"
            f"{db_config['host']}:3306/{db_config['database']}"
        )
        
        engine = create_engine(
            connection_string,
            pool_recycle=300,  # Recycle connections after 300 seconds (5 minutes)
            pool_pre_ping=True # Test connections before use
        )
        st.success("Database engine created successfully.")
        return engine
    except Exception as e:
        st.error(f"Error creating database engine: {e}")
        st.info("Please check your .streamlit/secrets.toml for correct Azure MySQL credentials and server firewall rules.")
        return None

# --- 2. Data Loading Functions ---
@st.cache_data(ttl=3600) # Cache data for 1 hour
def load_all_data(engine):
    """
    Loads all necessary dataframes from the MySQL database.
    Returns a dictionary of dataframes.
    """
    data = {}
    
    if engine is None:
        st.error("Cannot load data: Database engine is not initialized.")
        return data

    st.info("Loading `kor_ticker`...")
    try:
        data['ticker_list'] = pd.read_sql("""
            SELECT *
            FROM kor_ticker
            WHERE ê¸°ì¤€ì¼ = (SELECT MAX(ê¸°ì¤€ì¼) FROM kor_ticker)
            AND ì¢…ëª©êµ¬ë¶„ = 'ë³´í†µì£¼';
        """, con=engine)
        st.success(f"Loaded {len(data['ticker_list'])} ordinary tickers.")
    except Exception as e:
        st.error(f"Failed to load `kor_ticker`: {e}")
        data['ticker_list'] = pd.DataFrame()

    st.info("Loading `kor_fs` (Financial Statements)...")
    try:
        # Assuming 'ê³µì‹œêµ¬ë¶„' = 'q' for quarterly data
        data['fs_list'] = pd.read_sql("""
            SELECT *
            FROM kor_fs
            WHERE ê³„ì • IN ('ë‹¹ê¸°ìˆœì´ìµ', 'ë§¤ì¶œì´ì´ìµ', 'ì˜ì—…í™œë™ìœ¼ë¡œì¸í•œí˜„ê¸ˆíë¦„', 'ìì‚°', 'ìë³¸')
            AND ê³µì‹œêµ¬ë¶„ = 'q';
        """, con=engine)
        st.success(f"Loaded {len(data['fs_list'])} financial statement entries.")
    except Exception as e:
        st.error(f"Failed to load `kor_fs`: {e}")
        data['fs_list'] = pd.DataFrame()

    st.info("Loading `kor_value` (Valuation Data)...")
    try:
        data['value_list'] = pd.read_sql("""
            SELECT *
            FROM kor_value
            WHERE ê¸°ì¤€ì¼ = (SELECT MAX(ê¸°ì¤€ì¼) FROM kor_value);
        """, con=engine)
        st.success(f"Loaded {len(data['value_list'])} valuation entries.")
    except Exception as e:
        st.error(f"Failed to load `kor_value`: {e}")
        data['value_list'] = pd.DataFrame()

    st.info("Loading `kor_price` (Last 1 year of prices)...")
    try:
        # Changed 'ë‚ ì§œ' to 'ê¸°ì¤€ì¼' based on common table naming and previous discussions
        data['price_list'] = pd.read_sql("""
            SELECT ê¸°ì¤€ì¼ AS ë‚ ì§œ, ì¢…ê°€, ì¢…ëª©ì½”ë“œ
            FROM kor_price
            WHERE ê¸°ì¤€ì¼ >= (SELECT MAX(ê¸°ì¤€ì¼) - INTERVAL 1 YEAR FROM kor_price);
        """, con=engine)
        st.success(f"Loaded {len(data['price_list'])} price entries.")
    except Exception as e:
        st.error(f"Failed to load `kor_price`: {e}")
        data['price_list'] = pd.DataFrame()

    st.info("Loading `kor_sector`...")
    try:
        data['sector_list'] = pd.read_sql("""
            SELECT *
            FROM kor_sector
            WHERE ê¸°ì¤€ì¼ = (SELECT MAX(ê¸°ì¤€ì¼) FROM kor_sector);
        """, con=engine)
        st.success(f"Loaded {len(data['sector_list'])} sector entries.")
    except Exception as e:
        st.error(f"Failed to load `kor_sector`: {e}")
        data['sector_list'] = pd.DataFrame()
        
    return data

# --- 3. Streamlit Application ---

st.set_page_config(layout="wide", page_title="ì¬ë¬´ ë° ê°€ì¹˜ ë°ì´í„° ë¡œë”")

st.title("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°")
st.markdown("Azure Cloud MySQLì—ì„œ `kor_ticker`, `kor_fs`, `kor_value`, `kor_price`, `kor_sector` í…Œì´ë¸”ì˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ í‘œì‹œí•©ë‹ˆë‹¤.")

# Get the database engine
engine_instance = get_db_engine()

# Load all dataframes
loaded_data = load_all_data(engine_instance)

# Ensure the engine connection pool is closed after loading data (good practice)
if engine_instance:
    engine_instance.dispose()

st.subheader("ë°ì´í„° ë¡œë”© ê²°ê³¼:")

if not all(df.empty for df in loaded_data.values()):
    st.success("ëª¨ë“  ë°ì´í„° ë¡œë”© ì‹œë„ ì™„ë£Œ!")
else:
    st.warning("ì¼ë¶€ ë˜ëŠ” ëª¨ë“  ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìœ„ì— í‘œì‹œëœ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# Display head of each loaded DataFrame (for debugging/verification)
for df_name, df in loaded_data.items():
    if not df.empty:
        st.write(f"### {df_name} ({len(df)} rows)")
        st.dataframe(df.head())
    else:
        st.write(f"### {df_name} (No data loaded or DataFrame is empty)")

# Example of how you might start processing (similar to your original snippet)
# This part is just for demonstration; you'd integrate it into your full analysis.
st.subheader("ì˜ˆì‹œ: Tickerì™€ Value ë°ì´í„° ë³‘í•©")
if 'ticker_list' in loaded_data and 'value_list' in loaded_data and \
   not loaded_data['ticker_list'].empty and not loaded_data['value_list'].empty:
    
    value_list_df = loaded_data['value_list'].copy()
    # Apply your value cleaning logic
    value_list_df.loc[value_list_df['ê°’'] <= 0, 'ê°’'] = np.nan
    value_pivot = value_list_df.pivot(index='ì¢…ëª©ì½”ë“œ', columns='ì§€í‘œ', values='ê°’')
    
    # Ensure 'ì¢…ëª©ì½”ë“œ' is string type for merging if needed (good practice for IDs)
    loaded_data['ticker_list']['ì¢…ëª©ì½”ë“œ'] = loaded_data['ticker_list']['ì¢…ëª©ì½”ë“œ'].astype(str)
    value_pivot.index = value_pivot.index.astype(str)

    data_bind = loaded_data['ticker_list'][['ì¢…ëª©ì½”ë“œ', 'ì¢…ëª©ëª…', 'ì¢…ê°€']].merge(
                                                    value_pivot,
                                                    how='left',
                                                    on='ì¢…ëª©ì½”ë“œ')
    st.dataframe(data_bind.head())
else:
    st.info("`ticker_list` ë˜ëŠ” `value_list`ê°€ ì—†ì–´ ë³‘í•© ì˜ˆì‹œë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


st.sidebar.markdown("---")
st.sidebar.info("ì´ ì•±ì€ Azure MySQLì—ì„œ ë‹¤ì–‘í•œ ì£¼ì‹ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.")
st.sidebar.markdown("Â© 2025 Data Loader")
